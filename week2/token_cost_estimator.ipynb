{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "905fb459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiktoken import encoding_for_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7812ef8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = encoding_for_model(\"gpt-3.5\")\n",
    "model2 = encoding_for_model(\"gpt-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff695e6",
   "metadata": {},
   "source": [
    "### when passing name into tiktoken encoding model it gives more than 1 token based on lenght of the name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e777f545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "['jas', 'w', 'ab', 'iju']\n"
     ]
    }
   ],
   "source": [
    "text = \"jaswabiju\"\n",
    "encoding1 = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "encoding2 = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "token1 = encoding1.encode(text)\n",
    "token2 = encoding2.encode(text)\n",
    "\n",
    "print(len(token1))  # 6\n",
    "print(len(token2))  # 6\n",
    "print([encoding2.decode([t]) for t in token2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "315e1cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 'Hello, how are you doing today?'\n",
      "gpt-3.5 tokens (8): [9906, 11, 1268, 527, 499, 3815, 3432, 30]\n",
      "gpt-4   tokens (8): [9906, 11, 1268, 527, 499, 3815, 3432, 30]\n",
      "['Hello', ',', ' how', ' are', ' you', ' doing', ' today', '?']\n",
      "['Hello', ',', ' how', ' are', ' you', ' doing', ' today', '?']\n",
      "------------------------------------------------------------\n",
      "Text: '🎉👍😄!!??'\n",
      "gpt-3.5 tokens (10): [9468, 236, 231, 9468, 239, 235, 76460, 226, 3001, 7801]\n",
      "gpt-4   tokens (10): [9468, 236, 231, 9468, 239, 235, 76460, 226, 3001, 7801]\n",
      "['�', '�', '�', '�', '�', '�', '�', '�', '!!', '??']\n",
      "['�', '�', '�', '�', '�', '�', '�', '�', '!!', '??']\n",
      "------------------------------------------------------------\n",
      "Text: 'bioluminescentdinoflagellates'\n",
      "gpt-3.5 tokens (9): [8385, 1152, 1572, 1189, 73911, 1073, 13667, 616, 988]\n",
      "gpt-4   tokens (9): [8385, 1152, 1572, 1189, 73911, 1073, 13667, 616, 988]\n",
      "['bi', 'olum', 'ines', 'cent', 'din', 'of', 'lag', 'ell', 'ates']\n",
      "['bi', 'olum', 'ines', 'cent', 'din', 'of', 'lag', 'ell', 'ates']\n",
      "------------------------------------------------------------\n",
      "Text: 'state-of-the-art'\n",
      "gpt-3.5 tokens (4): [2513, 8838, 10826, 38921]\n",
      "gpt-4   tokens (4): [2513, 8838, 10826, 38921]\n",
      "['state', '-of', '-the', '-art']\n",
      "['state', '-of', '-the', '-art']\n",
      "------------------------------------------------------------\n",
      "Text: 'ThisIsCamelCaseText'\n",
      "gpt-3.5 tokens (6): [2028, 3957, 26479, 301, 4301, 1199]\n",
      "gpt-4   tokens (6): [2028, 3957, 26479, 301, 4301, 1199]\n",
      "['This', 'Is', 'Cam', 'el', 'Case', 'Text']\n",
      "['This', 'Is', 'Cam', 'el', 'Case', 'Text']\n",
      "------------------------------------------------------------\n",
      "Text: 'def count_tokens(text): return len(text.split())'\n",
      "gpt-3.5 tokens (10): [755, 1797, 29938, 7383, 1680, 471, 2479, 7383, 5402, 2189]\n",
      "gpt-4   tokens (10): [755, 1797, 29938, 7383, 1680, 471, 2479, 7383, 5402, 2189]\n",
      "['def', ' count', '_tokens', '(text', '):', ' return', ' len', '(text', '.split', '())']\n",
      "['def', ' count', '_tokens', '(text', '):', ' return', ' len', '(text', '.split', '())']\n",
      "------------------------------------------------------------\n",
      "Text: 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'\n",
      "gpt-3.5 tokens (6): [70540, 70540, 70540, 70540, 70540, 64]\n",
      "gpt-4   tokens (6): [70540, 70540, 70540, 70540, 70540, 64]\n",
      "['aaaaaaaa', 'aaaaaaaa', 'aaaaaaaa', 'aaaaaaaa', 'aaaaaaaa', 'a']\n",
      "['aaaaaaaa', 'aaaaaaaa', 'aaaaaaaa', 'aaaaaaaa', 'aaaaaaaa', 'a']\n",
      "------------------------------------------------------------\n",
      "Text: 'नमस्ते दुनिया'\n",
      "gpt-3.5 tokens (13): [61196, 88344, 79468, 31584, 97, 35470, 15272, 99, 73753, 61196, 43411, 107, 24810]\n",
      "gpt-4   tokens (13): [61196, 88344, 79468, 31584, 97, 35470, 15272, 99, 73753, 61196, 43411, 107, 24810]\n",
      "['न', 'म', 'स', '्�', '�', 'े', ' �', '�', 'ु', 'न', 'ि�', '�', 'ा']\n",
      "['न', 'म', 'स', '्�', '�', 'े', ' �', '�', 'ु', 'न', 'ि�', '�', 'ा']\n",
      "------------------------------------------------------------\n",
      "Text: 'こんにちは世界'\n",
      "gpt-3.5 tokens (4): [90115, 3574, 244, 98220]\n",
      "gpt-4   tokens (4): [90115, 3574, 244, 98220]\n",
      "['こんにちは', '�', '�', '界']\n",
      "['こんにちは', '�', '�', '界']\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def compare_token_counts(text: str):\n",
    "    enc_35 = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    enc_4 = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "    tokens_35 = enc_35.encode(text)\n",
    "    tokens_4 = enc_4.encode(text)\n",
    "\n",
    "    print(f\"Text: {text!r}\")\n",
    "    print(f\"gpt-3.5 tokens ({len(tokens_35)}): {tokens_35}\")\n",
    "    print(f\"gpt-4   tokens ({len(tokens_4)}): {tokens_4}\")\n",
    "    print([enc_35.decode([t]) for t in tokens_35])\n",
    "    print([enc_4.decode([t]) for t in tokens_4])\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Basic sentence\n",
    "compare_token_counts(\"Hello, how are you doing today?\")\n",
    "\n",
    "# Emoji and punctuation\n",
    "compare_token_counts(\"🎉👍😄!!??\")\n",
    "\n",
    "# Long compound word (not in vocabulary)\n",
    "compare_token_counts(\"bioluminescentdinoflagellates\")\n",
    "\n",
    "# Hyphenated word\n",
    "compare_token_counts(\"state-of-the-art\")\n",
    "\n",
    "# CamelCase\n",
    "compare_token_counts(\"ThisIsCamelCaseText\")\n",
    "\n",
    "# Code snippet\n",
    "compare_token_counts(\"def count_tokens(text): return len(text.split())\")\n",
    "\n",
    "# Repeated characters\n",
    "compare_token_counts(\"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\")\n",
    "\n",
    "# Non-English text\n",
    "compare_token_counts(\"नमस्ते दुनिया\")  # Hindi\n",
    "compare_token_counts(\"こんにちは世界\")   # Japanese\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcebce8",
   "metadata": {},
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "daf432e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List, Dict\n",
    "from tiktoken import encoding_for_model\n",
    "\n",
    "def count_chat_token(model=\"gpt-3.5\",text=Union[str, List[Dict[str,str]]]) -> int:\n",
    "    encoding = encoding_for_model(model)\n",
    "    if model == \"gpt-3.5\":\n",
    "        token_per_message = 4\n",
    "        token_per_name = -1\n",
    "    elif model == \"gpt-4\":\n",
    "        token_per_message = 3\n",
    "        token_per_name = 1\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Token counting not implemented for {model}\")\n",
    "\n",
    "    num_token = 0\n",
    "    if isinstance(text, str):\n",
    "        \n",
    "        num_token += token_per_message\n",
    "        num_token += len(encoding.encode(text))\n",
    "        num_token += 3\n",
    "        return num_token\n",
    "\n",
    "    elif isinstance(text,list):\n",
    "        for msg in text:\n",
    "            num_token += token_per_message\n",
    "            for key,value in msg.items():\n",
    "\n",
    "                num_token += len(encoding.encode(value))\n",
    "                print(value,len(encoding.encode(value)))\n",
    "                \n",
    "                if key == \"name\":\n",
    "                    num_token += token_per_name\n",
    "        num_token += 3\n",
    "        return num_token\n",
    "\n",
    "    else:\n",
    "        raise TypeError(f\"unsupported input type\")\n",
    "\n",
    "            \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fad5442d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user 1\n",
      "hello 1\n",
      "user 1\n",
      "how are you 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"hello\"},\n",
    "    {\"role\": \"user\", \"content\": \"how are you\"},\n",
    "\n",
    "]\n",
    "count_chat_token(\"gpt-3.5\",messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e3bc3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c56f139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234b318a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fralab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
